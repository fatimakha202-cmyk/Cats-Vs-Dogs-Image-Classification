{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatimakha202-cmyk/Cats-Vs-Dogs-Image-Classification/blob/master/2cats_vs_dogs_image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azAipXPeaHZ0"
      },
      "source": [
        "Cat Dog Classification\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Step 1: Install necessary libraries\n",
        "# ------------------------------\n",
        "!pip install tensorflow matplotlib numpy opencv-python\n",
        "\n",
        "# ------------------------------\n",
        "# Step 2: Import dependencies\n",
        "# ------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# ------------------------------\n",
        "# Step 3: Verify imports\n",
        "# ------------------------------\n",
        "print(\"All dependencies installed and imported successfully!\")\n",
        "print(\"TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ccJxIrepdR",
        "outputId": "ec009084-36be-40c8-a8af-5dfe3fb9848b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "All dependencies installed and imported successfully!\n",
            "TensorFlow version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5z5t-BLoSL4",
        "outputId": "ceffed03-9b57-4248-9f78-3a367c26c7a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fatimakha202-cmyk/Cats-Vs-Dogs-Image-Classification.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9muFQnOmYXG",
        "outputId": "3479c015-68a0-4d36-a614-cbaf44453b5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Cats-Vs-Dogs-Image-Classification' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ncgeC9WddA9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca84ff4-f94f-402e-bbbb-cd8252618297"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-g-6ot_aHZ9"
      },
      "source": [
        "#### Define some mathematical functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "ZsXn4t72aHZ-"
      },
      "outputs": [],
      "source": [
        "# Here 0 means Cat and 1 means Dog\n",
        "CAT = 0\n",
        "DOG = 1\n",
        "#Returns whether the low memory mode is used.\n",
        "IS_LOW_MEMORY_MODE = True\n",
        "#current working directory of a process.\n",
        "cwd = os.getcwd()\n",
        "#This method is called when RandomState is initialized\n",
        "np.random.seed(2124)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "h_UMjbf_aHZ-"
      },
      "outputs": [],
      "source": [
        "#Method to prepare a file\n",
        "def prepare_file():\n",
        "  file_list = ['train','test']\n",
        "  flag = True\n",
        "\n",
        "  # Path to the data directory within the cloned repository\n",
        "  repo_data_path = os.path.join(cwd, 'Cats-Vs-Dogs-Image-Classification', 'data')\n",
        "\n",
        "  # Ensure the target extraction directory exists\n",
        "  target_data_dir = os.path.join(cwd, 'data')\n",
        "  os.makedirs(target_data_dir, exist_ok=True)\n",
        "\n",
        "  for filename_prefix in file_list:\n",
        "    zip_filename = filename_prefix + '.zip'\n",
        "    zip_filepath = os.path.join(repo_data_path, zip_filename)\n",
        "\n",
        "    # Path to extract images for current file_list item (e.g., 'train' or 'test')\n",
        "    extract_path = os.path.join(target_data_dir, filename_prefix)\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "    print(f\"Extracting {zip_filepath} to {extract_path}\")\n",
        "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_path)\n",
        "\n",
        "  return flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "GKxVRgNzaHZ_"
      },
      "outputs": [],
      "source": [
        "#Method to read the image label\n",
        "def read_image_label_list(folder_dir):\n",
        "    dir_list = os.listdir(os.path.join(cwd,folder_dir))\n",
        "    filenames = []\n",
        "    labels = []\n",
        "\n",
        "    for i, d in enumerate(dir_list):\n",
        "        if re.search(\"train\",folder_dir):\n",
        "            if re.search(\"cat\", d):\n",
        "                labels.append(CAT)\n",
        "            else:\n",
        "                labels.append(DOG)\n",
        "        else:\n",
        "            labels.append(-1)\n",
        "        filenames.append(os.path.join(cwd, folder_dir, d))\n",
        "    return filenames, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "id": "z4YxRtjgaHaA"
      },
      "outputs": [],
      "source": [
        "#Method to read the image from disk\n",
        "def read_images_from_disk(input_queue):\n",
        "    filename = input_queue[0]\n",
        "    label = input_queue[1]\n",
        "\n",
        "    file_contents = tf.read_file(filename)\n",
        "    image = tf.image.decode_image(file_contents, channels=3)\n",
        "    image.set_shape([None, None, 3])\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "xM4WbqE5aHaA"
      },
      "outputs": [],
      "source": [
        "#Method to generate input function\n",
        "def gen_input_fn(image_list, label_list, batch_size, shuffle):\n",
        "\n",
        "    def input_fn():\n",
        "        images = tf.convert_to_tensor(image_list, dtype=tf.string)\n",
        "        labels = tf.convert_to_tensor(label_list, dtype=tf.int32)\n",
        "\n",
        "        input_queue = tf.train.slice_input_producer(\n",
        "            [images, labels],\n",
        "            capacity=batch_size * 5,\n",
        "            shuffle=shuffle,\n",
        "            name=\"file_input_queue\"\n",
        "        )\n",
        "\n",
        "        image, label = read_images_from_disk(input_queue)\n",
        "        image = tf.image.resize_images(image, (224, 224), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "        image_batch, label_batch = tf.train.batch(\n",
        "            [image, label],\n",
        "            batch_size=batch_size,\n",
        "            num_threads=1,\n",
        "            name=\"batch_queue\",\n",
        "            capacity=batch_size * 10,\n",
        "            allow_smaller_final_batch = False\n",
        "        )\n",
        "\n",
        "        return (\n",
        "            tf.identity(image_batch, name=\"features\"),\n",
        "            tf.identity(label_batch, name=\"label\")\n",
        "        )\n",
        "\n",
        "    return input_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "id": "PK4cmqQzaHaB"
      },
      "outputs": [],
      "source": [
        "#Method to train a valid input function\n",
        "def train_valid_input_fn(data_dir, train_batch_size, valid_batch_size=None):\n",
        "    img, labels = read_image_label_list(data_dir)\n",
        "    img = np.array(img)\n",
        "    labels = np.array(labels)\n",
        "    data_size = img.shape[0]\n",
        "\n",
        "    print(\"Data size: \" + str(data_size))\n",
        "    split = int(0.7 * data_size)\n",
        "\n",
        "    random_seq = np.random.permutation(data_size)\n",
        "\n",
        "    img = img[random_seq]\n",
        "    labels = labels[random_seq]\n",
        "\n",
        "    if valid_batch_size == None:\n",
        "        valid_batch_size = train_batch_size\n",
        "\n",
        "    return (\n",
        "        gen_input_fn(img[0:split], labels[0:split], train_batch_size, shuffle = True),\n",
        "        gen_input_fn(img[split:], labels[split:], valid_batch_size, shuffle = False)\n",
        "           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "9SQ5fxAEaHaC"
      },
      "outputs": [],
      "source": [
        "#Method to test input function\n",
        "def test_input_fn(data_dir,batch_size):\n",
        "    image_list, label_list = read_image_label_list(data_dir)\n",
        "    return gen_input_fn(image_list, label_list, batch_size, shuffle = False), image_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7crtrW0UaHaC"
      },
      "source": [
        "### Data visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "id": "hCBn4uk2aHaD"
      },
      "outputs": [],
      "source": [
        "#Method to plot data\n",
        "def plot_img(data, label=None):\n",
        "    plt.ion()\n",
        "    plt.figure()\n",
        "    plt.imshow(data)\n",
        "    if label is not None:\n",
        "        plt.title(label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def preview_img_tf2(batch_size=5):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    import cv2\n",
        "\n",
        "    path = '/content/data/train'\n",
        "    classes = os.listdir(path)\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label, cls in enumerate(classes):\n",
        "        cls_path = os.path.join(path, cls)\n",
        "        for img_name in os.listdir(cls_path)[:batch_size]:\n",
        "            img_path = os.path.join(cls_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (150,150))\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(str(labels[i]))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "preview_img_tf2()"
      ],
      "metadata": {
        "id": "Bc4ZZjkeqVPK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if prepare_file():\n",
        "    print(\"Files extracted successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "3o0B2hTjr8Fj",
        "outputId": "e15e4e15-f474-4bd7-c436-f403296c6749"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/Cats-Vs-Dogs-Image-Classification/data/train.zip to /content/data/train\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'zipfile' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1493959011.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mprepare_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files extracted successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-674503251.py\u001b[0m in \u001b[0;36mprepare_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extracting {zip_filepath} to {extract_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'zipfile' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrKFhYjJaHaE"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FWlodRTAaHaE"
      },
      "outputs": [],
      "source": [
        "#Cat-Dog Method Declaration\n",
        "def catdog_model(inputs, is_training):\n",
        "    with tf.variable_scope('catdog', values=[inputs]):\n",
        "        with slim.arg_scope(\n",
        "            [slim.conv2d, slim.fully_connected],\n",
        "            activation_fn=tf.nn.relu6,\n",
        "            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01)):\n",
        "\n",
        "            net = inputs\n",
        "\n",
        "            if IS_LOW_MEMORY_MODE == False:\n",
        "                net = slim.repeat(net, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "\n",
        "                net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "\n",
        "                net = slim.repeat(net, 4, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "                net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv4')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
        "                net = slim.repeat(net, 4, slim.conv2d, 512, [3, 3], scope='conv5')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
        "\n",
        "                net = tf.reshape(net, [-1, 7 * 7 * 512])\n",
        "\n",
        "                net = slim.fully_connected(net, 2048, scope='fc6')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout6')\n",
        "\n",
        "                net = slim.fully_connected(net, 2048, scope='fc7')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout7')\n",
        "\n",
        "                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc8')\n",
        "\n",
        "            else:\n",
        "                # Model for my Mac T_T\n",
        "                net = tf.image.resize_images(net, (72, 72), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "                net = slim.repeat(net, 1, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "\n",
        "                net = slim.repeat(net, 1, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "\n",
        "                net = slim.repeat(net, 2, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "                net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "\n",
        "                net = tf.reshape(net, [-1, 9 * 9 * 256])\n",
        "\n",
        "                net = slim.fully_connected(net, 1024, scope='fc4')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout4')\n",
        "\n",
        "                net = slim.fully_connected(net, 1024, scope='fc5')\n",
        "                net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout5')\n",
        "\n",
        "                net = slim.fully_connected(net, 2, activation_fn=None, scope='fc6')\n",
        "\n",
        "            return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NDAm1ulAaHaF"
      },
      "outputs": [],
      "source": [
        "#Cat-Dog Model function\n",
        "def catdog_model_fn(features, labels, mode, params):\n",
        "\n",
        "    is_training = False\n",
        "    if mode == learn.ModeKeys.TRAIN:\n",
        "        is_training = True\n",
        "\n",
        "    output = catdog_model(features, is_training)\n",
        "\n",
        "    log_loss = None\n",
        "    train_op = None\n",
        "    eval_metric_ops = None\n",
        "\n",
        "    softmax_predictions = tf.nn.softmax(output)\n",
        "\n",
        "    if mode != learn.ModeKeys.INFER:\n",
        "        onehot_labels = tf.one_hot(\n",
        "            tf.cast(labels, tf.int32),\n",
        "            depth = 2\n",
        "        )\n",
        "        log_loss = tf.identity(\n",
        "            tf.losses.log_loss(\n",
        "                onehot_labels,\n",
        "                tf.nn.softmax(output),\n",
        "                reduction = tf.losses.Reduction.MEAN\n",
        "            ),\n",
        "            name = \"log_loss_tensor\"\n",
        "        )\n",
        "        eval_metric_ops = {\n",
        "            \"log_loss\": log_loss\n",
        "        }\n",
        "\n",
        "    if mode == learn.ModeKeys.TRAIN:\n",
        "        train_op = tf.contrib.layers.optimize_loss(\n",
        "            loss = log_loss,\n",
        "            global_step = tf.contrib.framework.get_global_step(),\n",
        "            learning_rate = params['learning_rate'],\n",
        "            optimizer = \"Adam\"\n",
        "        )\n",
        "\n",
        "    predictions = {\n",
        "        'predict': softmax_predictions\n",
        "    }\n",
        "\n",
        "    return model_fn.ModelFnOps(\n",
        "        mode = mode,\n",
        "        predictions = predictions,\n",
        "        loss = log_loss,\n",
        "        train_op = train_op,\n",
        "        eval_metric_ops = eval_metric_ops\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": false,
        "id": "BV2ItyLAaHaF",
        "outputId": "e494adc3-86ea-4f22-fb94-d99a71edfea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'logging'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3894759643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIS_LOW_MEMORY_MODE\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'logging'"
          ]
        }
      ],
      "source": [
        "#Feature Engineering function\n",
        "def feature_engineering_fn(features, labels):\n",
        "    features = tf.to_float(features)\n",
        "    features = tf.map_fn(tf.image.per_image_standardization, features)\n",
        "    return features, labels\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "model_path = 'model' if IS_LOW_MEMORY_MODE else 'model'\n",
        "classifier = learn.Estimator(\n",
        "    model_fn = catdog_model_fn,\n",
        "    model_dir = model_path,\n",
        "    config = run_config(\n",
        "        save_summary_steps = 10,\n",
        "        keep_checkpoint_max = 3,\n",
        "        save_checkpoints_steps = 75\n",
        "    ),\n",
        "    feature_engineering_fn = feature_engineering_fn,\n",
        "    params = {\n",
        "        'learning_rate': 0.01\n",
        "    }\n",
        ")\n",
        "\n",
        "# Correct path to the extracted training data\n",
        "train_input_fn, validate_input_fn = train_valid_input_fn('data/train', 32, 64)\n",
        "\n",
        "logging_hook = tf.train.LoggingTensorHook(\n",
        "    tensors = {\n",
        "        'log_loss': 'log_loss_tensor'\n",
        "    },\n",
        "    every_n_iter = 3\n",
        ")\n",
        "\n",
        "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
        "    input_fn = validate_input_fn,\n",
        "    eval_steps = 30,\n",
        "    every_n_steps = 100,\n",
        "    name = 'Validatation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX3ypK16aHaG"
      },
      "source": [
        "#### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "egiEkkfGaHaG",
        "outputId": "2f3d2827-3e5f-4abd-d339-d54234fe415f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-200\n",
            "INFO:tensorflow:Saving checkpoints for 201 into model/model.ckpt.\n",
            "INFO:tensorflow:log_loss = 6.5479765\n",
            "INFO:tensorflow:Starting evaluation at 2018-02-06-15:59:45\n",
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-201\n",
            "INFO:tensorflow:Evaluation [1/30]\n",
            "INFO:tensorflow:Evaluation [2/30]\n",
            "INFO:tensorflow:Evaluation [3/30]\n",
            "INFO:tensorflow:Evaluation [4/30]\n",
            "INFO:tensorflow:Evaluation [5/30]\n",
            "INFO:tensorflow:Evaluation [6/30]\n",
            "INFO:tensorflow:Evaluation [7/30]\n",
            "INFO:tensorflow:Evaluation [8/30]\n",
            "INFO:tensorflow:Evaluation [9/30]\n",
            "INFO:tensorflow:Evaluation [10/30]\n",
            "INFO:tensorflow:Evaluation [11/30]\n",
            "INFO:tensorflow:Evaluation [12/30]\n",
            "INFO:tensorflow:Evaluation [13/30]\n",
            "INFO:tensorflow:Evaluation [14/30]\n",
            "INFO:tensorflow:Evaluation [15/30]\n",
            "INFO:tensorflow:Evaluation [16/30]\n",
            "INFO:tensorflow:Evaluation [17/30]\n",
            "INFO:tensorflow:Evaluation [18/30]\n",
            "INFO:tensorflow:Evaluation [19/30]\n",
            "INFO:tensorflow:Evaluation [20/30]\n",
            "INFO:tensorflow:Evaluation [21/30]\n",
            "INFO:tensorflow:Evaluation [22/30]\n",
            "INFO:tensorflow:Evaluation [23/30]\n",
            "INFO:tensorflow:Evaluation [24/30]\n",
            "INFO:tensorflow:Evaluation [25/30]\n",
            "INFO:tensorflow:Evaluation [26/30]\n",
            "INFO:tensorflow:Evaluation [27/30]\n",
            "INFO:tensorflow:Evaluation [28/30]\n",
            "INFO:tensorflow:Evaluation [29/30]\n",
            "INFO:tensorflow:Evaluation [30/30]\n",
            "INFO:tensorflow:Finished evaluation at 2018-02-06-16:01:05\n",
            "INFO:tensorflow:Saving dict for global step 201: global_step = 201, log_loss = 7.555359, loss = 8.210157\n",
            "INFO:tensorflow:Validation (step 201): log_loss = 7.555359, loss = 8.210157, global_step = 201\n",
            "INFO:tensorflow:loss = 6.5479765, step = 201\n",
            "INFO:tensorflow:log_loss = 7.555357 (92.375 sec)\n",
            "INFO:tensorflow:log_loss = 8.059048 (11.834 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (11.838 sec)\n",
            "INFO:tensorflow:log_loss = 9.57012 (11.902 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (12.013 sec)\n",
            "INFO:tensorflow:log_loss = 8.059048 (12.696 sec)\n",
            "INFO:tensorflow:log_loss = 7.0516667 (11.472 sec)\n",
            "INFO:tensorflow:log_loss = 7.5553575 (12.741 sec)\n",
            "INFO:tensorflow:log_loss = 10.073811 (12.404 sec)\n",
            "INFO:tensorflow:log_loss = 9.066429 (11.569 sec)\n",
            "INFO:tensorflow:log_loss = 6.044286 (12.372 sec)\n",
            "INFO:tensorflow:log_loss = 7.0516667 (12.370 sec)\n",
            "INFO:tensorflow:log_loss = 10.577501 (12.698 sec)\n",
            "INFO:tensorflow:log_loss = 9.066429 (12.242 sec)\n",
            "INFO:tensorflow:log_loss = 9.066429 (12.526 sec)\n",
            "INFO:tensorflow:log_loss = 5.036905 (13.085 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (11.796 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (11.581 sec)\n",
            "INFO:tensorflow:log_loss = 10.073811 (11.901 sec)\n",
            "INFO:tensorflow:log_loss = 10.073811 (11.899 sec)\n",
            "INFO:tensorflow:log_loss = 9.066429 (12.681 sec)\n",
            "INFO:tensorflow:log_loss = 11.081192 (12.459 sec)\n",
            "INFO:tensorflow:log_loss = 9.066429 (12.285 sec)\n",
            "INFO:tensorflow:log_loss = 7.051667 (12.054 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 276 into model/model.ckpt.\n",
            "INFO:tensorflow:log_loss = 8.562738 (15.835 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (13.310 sec)\n",
            "INFO:tensorflow:log_loss = 6.5479765 (13.815 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (12.364 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (12.084 sec)\n",
            "INFO:tensorflow:log_loss = 8.562738 (12.810 sec)\n",
            "INFO:tensorflow:log_loss = 5.036905 (13.451 sec)\n",
            "INFO:tensorflow:log_loss = 7.555357 (12.162 sec)\n",
            "INFO:tensorflow:log_loss = 7.555357 (12.331 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 300 into model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 7.555357.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Estimator(params={'learning_rate': 0.01})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "classifier.fit(\n",
        "    input_fn = train_input_fn,\n",
        "    steps = 100,\n",
        "    monitors = [logging_hook, validation_monitor]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJbyVmmEaHaG",
        "outputId": "c63aec94-c426-4876-8219-be74ce0e7320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2018-02-06-16:08:01\n",
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-300\n",
            "INFO:tensorflow:Evaluation [1/75]\n",
            "INFO:tensorflow:Evaluation [2/75]\n",
            "INFO:tensorflow:Evaluation [3/75]\n",
            "INFO:tensorflow:Evaluation [4/75]\n",
            "INFO:tensorflow:Evaluation [5/75]\n",
            "INFO:tensorflow:Evaluation [6/75]\n",
            "INFO:tensorflow:Evaluation [7/75]\n",
            "INFO:tensorflow:Evaluation [8/75]\n",
            "INFO:tensorflow:Evaluation [9/75]\n",
            "INFO:tensorflow:Evaluation [10/75]\n",
            "INFO:tensorflow:Evaluation [11/75]\n",
            "INFO:tensorflow:Evaluation [12/75]\n",
            "INFO:tensorflow:Evaluation [13/75]\n",
            "INFO:tensorflow:Evaluation [14/75]\n",
            "INFO:tensorflow:Evaluation [15/75]\n",
            "INFO:tensorflow:Evaluation [16/75]\n",
            "INFO:tensorflow:Evaluation [17/75]\n",
            "INFO:tensorflow:Evaluation [18/75]\n",
            "INFO:tensorflow:Evaluation [19/75]\n",
            "INFO:tensorflow:Evaluation [20/75]\n",
            "INFO:tensorflow:Evaluation [21/75]\n",
            "INFO:tensorflow:Evaluation [22/75]\n",
            "INFO:tensorflow:Evaluation [23/75]\n",
            "INFO:tensorflow:Evaluation [24/75]\n",
            "INFO:tensorflow:Evaluation [25/75]\n",
            "INFO:tensorflow:Evaluation [26/75]\n",
            "INFO:tensorflow:Evaluation [27/75]\n",
            "INFO:tensorflow:Evaluation [28/75]\n",
            "INFO:tensorflow:Evaluation [29/75]\n",
            "INFO:tensorflow:Evaluation [30/75]\n",
            "INFO:tensorflow:Evaluation [31/75]\n",
            "INFO:tensorflow:Evaluation [32/75]\n",
            "INFO:tensorflow:Evaluation [33/75]\n",
            "INFO:tensorflow:Evaluation [34/75]\n",
            "INFO:tensorflow:Evaluation [35/75]\n",
            "INFO:tensorflow:Evaluation [36/75]\n",
            "INFO:tensorflow:Evaluation [37/75]\n",
            "INFO:tensorflow:Evaluation [38/75]\n",
            "INFO:tensorflow:Evaluation [39/75]\n",
            "INFO:tensorflow:Evaluation [40/75]\n",
            "INFO:tensorflow:Evaluation [41/75]\n",
            "INFO:tensorflow:Evaluation [42/75]\n",
            "INFO:tensorflow:Evaluation [43/75]\n",
            "INFO:tensorflow:Evaluation [44/75]\n",
            "INFO:tensorflow:Evaluation [45/75]\n",
            "INFO:tensorflow:Evaluation [46/75]\n",
            "INFO:tensorflow:Evaluation [47/75]\n",
            "INFO:tensorflow:Evaluation [48/75]\n",
            "INFO:tensorflow:Evaluation [49/75]\n",
            "INFO:tensorflow:Evaluation [50/75]\n",
            "INFO:tensorflow:Evaluation [51/75]\n",
            "INFO:tensorflow:Evaluation [52/75]\n",
            "INFO:tensorflow:Evaluation [53/75]\n",
            "INFO:tensorflow:Evaluation [54/75]\n",
            "INFO:tensorflow:Evaluation [55/75]\n",
            "INFO:tensorflow:Evaluation [56/75]\n",
            "INFO:tensorflow:Evaluation [57/75]\n",
            "INFO:tensorflow:Evaluation [58/75]\n",
            "INFO:tensorflow:Evaluation [59/75]\n",
            "INFO:tensorflow:Evaluation [60/75]\n",
            "INFO:tensorflow:Evaluation [61/75]\n",
            "INFO:tensorflow:Evaluation [62/75]\n",
            "INFO:tensorflow:Evaluation [63/75]\n",
            "INFO:tensorflow:Evaluation [64/75]\n",
            "INFO:tensorflow:Evaluation [65/75]\n",
            "INFO:tensorflow:Evaluation [66/75]\n",
            "INFO:tensorflow:Evaluation [67/75]\n",
            "INFO:tensorflow:Evaluation [68/75]\n",
            "INFO:tensorflow:Evaluation [69/75]\n",
            "INFO:tensorflow:Evaluation [70/75]\n",
            "INFO:tensorflow:Evaluation [71/75]\n",
            "INFO:tensorflow:Evaluation [72/75]\n",
            "INFO:tensorflow:Evaluation [73/75]\n",
            "INFO:tensorflow:Evaluation [74/75]\n",
            "INFO:tensorflow:Evaluation [75/75]\n",
            "INFO:tensorflow:Finished evaluation at 2018-02-06-16:11:15\n",
            "INFO:tensorflow:Saving dict for global step 300: global_step = 300, log_loss = 9.066431, loss = 8.163145\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'global_step': 300, 'log_loss': 9.066431, 'loss': 8.163145}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Model Evaluation\n",
        "classifier.evaluate(\n",
        "    input_fn = validate_input_fn,\n",
        "    steps = 75\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_N0gsGhaHaG"
      },
      "source": [
        "#### Final Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "o8468V4kaHaH",
        "outputId": "270992f3-94bd-4757-eccb-692ace31558a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data/test'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4273518460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Print the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Correct path to the extracted test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_test_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_test_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1387855422.py\u001b[0m in \u001b[0;36mtest_input_fn\u001b[0;34m(data_dir, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Method to test input function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image_label_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4234735875.py\u001b[0m in \u001b[0;36mread_image_label_list\u001b[0;34m(folder_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Method to read the image label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_image_label_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdir_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/test'"
          ]
        }
      ],
      "source": [
        "#Print the result\n",
        "# Correct path to the extracted test data\n",
        "test_fn, image_test_list = test_input_fn('data/test',32)\n",
        "test_n = len(image_test_list)\n",
        "\n",
        "print(\"Test size: %d\" % test_n)\n",
        "\n",
        "result_file = open(os.path.join(cwd, 'result/result.txt'),'w+')\n",
        "result_file.write('id,label\\n')\n",
        "\n",
        "predictions = classifier.predict(input_fn = test_fn, as_iterable=True)\n",
        "for i, p in enumerate(predictions):\n",
        "    if i >= test_n:\n",
        "        break\n",
        "\n",
        "    id = image_test_list[i].split(\"/\")[-1]\n",
        "    id = id.split(\".\")[0]\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(\"Predict %d %s: %f\" % (i,image_test_list[i],p[\"predict\"][1]))\n",
        "\n",
        "    result_file.write(\"%s,%f\\n\" % (id, p[\"predict\"][1]))\n",
        "\n",
        "result_file.flush()\n",
        "result_file.close()\n",
        "print('Finish!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ha5Yiw_YaHaH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}